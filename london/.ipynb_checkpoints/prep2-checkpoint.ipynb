{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Stage 2 START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/jbmai_sai/Documents/london/preprocess_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>space</th>\n",
       "      <th>description</th>\n",
       "      <th>experiences_offered</th>\n",
       "      <th>notes</th>\n",
       "      <th>transit</th>\n",
       "      <th>access</th>\n",
       "      <th>interaction</th>\n",
       "      <th>house_rules</th>\n",
       "      <th>host_since</th>\n",
       "      <th>host_about</th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_neighbourhood</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>host_verifications</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>is_location_exact</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>amenities</th>\n",
       "      <th>price</th>\n",
       "      <th>security_deposit</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>guests_included</th>\n",
       "      <th>extra_people</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>minimum_minimum_nights</th>\n",
       "      <th>maximum_minimum_nights</th>\n",
       "      <th>minimum_maximum_nights</th>\n",
       "      <th>maximum_maximum_nights</th>\n",
       "      <th>minimum_nights_avg_ntm</th>\n",
       "      <th>maximum_nights_avg_ntm</th>\n",
       "      <th>calendar_updated</th>\n",
       "      <th>has_availability</th>\n",
       "      <th>availability_30</th>\n",
       "      <th>availability_60</th>\n",
       "      <th>availability_90</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>calendar_last_scraped</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>number_of_reviews_ltm</th>\n",
       "      <th>first_review</th>\n",
       "      <th>last_review</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>review_scores_accuracy</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>requires_license</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>is_business_travel_ready</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>require_guest_profile_picture</th>\n",
       "      <th>require_guest_phone_verification</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>host_name_cat</th>\n",
       "      <th>host_country</th>\n",
       "      <th>host_city</th>\n",
       "      <th>states</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Holiday London DB Room Let-on going</td>\n",
       "      <td>Hello Everyone, I'm offering my lovely double ...</td>\n",
       "      <td>My bright double bedroom with a large window h...</td>\n",
       "      <td>business</td>\n",
       "      <td>For art lovers I can give guest my Tate Member...</td>\n",
       "      <td>The flat only a 10 minute walk to Finsbury Par...</td>\n",
       "      <td>Guest will have access to the self catering ki...</td>\n",
       "      <td>I like to have little chats with my guest over...</td>\n",
       "      <td>I'm an artist and have my artwork up on the wa...</td>\n",
       "      <td>3658</td>\n",
       "      <td>I am a Multi-Media Visual Artist and Creative ...</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>86.0</td>\n",
       "      <td>f</td>\n",
       "      <td>193</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['email', 'phone', 'facebook', 'reviews']</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>73.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>Greater London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>51.568020000000004</td>\n",
       "      <td>-0.11121</td>\n",
       "      <td>t</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>{TV,\"Cable TV\",Wifi,Kitchen,\"Paid parking off ...</td>\n",
       "      <td>65.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>t</td>\n",
       "      <td>19.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>2019-07-11</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3336</td>\n",
       "      <td>47</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>518.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>988.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Bright Chelsea  Apartment. Chelsea!</td>\n",
       "      <td>Bright Chelsea Apartment  This is a bright one...</td>\n",
       "      <td>Lots of windows and light.  St Luke's Gardens ...</td>\n",
       "      <td>romantic</td>\n",
       "      <td>The building next door is in the process of be...</td>\n",
       "      <td>The underground stations are South Kensington ...</td>\n",
       "      <td>There are two wardrobes for guests exclusive u...</td>\n",
       "      <td>If I am in the country I like to welcome my gu...</td>\n",
       "      <td>NO SMOKING PLEASE.. No unauthorised guests. No...</td>\n",
       "      <td>3846</td>\n",
       "      <td>English, grandmother,  I have travelled quite ...</td>\n",
       "      <td>within a day</td>\n",
       "      <td>100.0</td>\n",
       "      <td>t</td>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['email', 'phone', 'reviews', 'jumio', 'govern...</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>110.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>none</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>51.48796</td>\n",
       "      <td>-0.16898</td>\n",
       "      <td>t</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>{TV,\"Cable TV\",Internet,Wifi,\"Air conditioning...</td>\n",
       "      <td>100.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>t</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>2019-07-11</td>\n",
       "      <td>85.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3422</td>\n",
       "      <td>201</td>\n",
       "      <td>96.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>strict_14_with_grace_period</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>10239.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>871.0</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Superb 3-Bed/2 Bath &amp; Wifi: Trendy W1</td>\n",
       "      <td>Ready again from June 2018 for bookings after ...</td>\n",
       "      <td>Open from June 2018 after a 3-year break, we a...</td>\n",
       "      <td>none</td>\n",
       "      <td>This property has new flooring throughout. Gue...</td>\n",
       "      <td>You can walk to tourist London or take numerou...</td>\n",
       "      <td>Full use of whole independent apartment</td>\n",
       "      <td>Always available by email or phone (before, du...</td>\n",
       "      <td>The apartment benefits from new flooring throu...</td>\n",
       "      <td>3522</td>\n",
       "      <td>We are Liz and Jack.  We manage a number of ho...</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>85.0</td>\n",
       "      <td>t</td>\n",
       "      <td>110</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>['email', 'phone', 'reviews', 'jumio', 'offlin...</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>35.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>Fitzrovia</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>51.52098</td>\n",
       "      <td>-0.14002</td>\n",
       "      <td>t</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>{TV,Wifi,Kitchen,\"Paid parking off premises\",E...</td>\n",
       "      <td>300.00</td>\n",
       "      <td>350.00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>365</td>\n",
       "      <td>365.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>today</td>\n",
       "      <td>t</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>2019-07-11</td>\n",
       "      <td>41.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3012</td>\n",
       "      <td>156</td>\n",
       "      <td>94.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>strict_14_with_grace_period</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>7459.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>988.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Battersea bedroom &amp; office w parking shared ga...</td>\n",
       "      <td>- End of terrace two bedroom house close to So...</td>\n",
       "      <td>Artist house, bright high ceiling rooms, priva...</td>\n",
       "      <td>family</td>\n",
       "      <td>- Please have a profile or tell us more about ...</td>\n",
       "      <td>- 5 mins walk to Battersea Park, 15 mins walk ...</td>\n",
       "      <td>- there is a communal garden in our complex - ...</td>\n",
       "      <td>We rent out our house only when we are away. T...</td>\n",
       "      <td>A house manual will be emailed once a booking ...</td>\n",
       "      <td>3707</td>\n",
       "      <td>I've been using Airbnb for a while now, both a...</td>\n",
       "      <td>within a day</td>\n",
       "      <td>100.0</td>\n",
       "      <td>f</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['email', 'phone', 'reviews', 'jumio', 'offlin...</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>84.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>none</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>51.47298</td>\n",
       "      <td>-0.16376</td>\n",
       "      <td>t</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>{TV,\"Cable TV\",Internet,Wifi,Kitchen,\"Free par...</td>\n",
       "      <td>175.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1125</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>4 months ago</td>\n",
       "      <td>t</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>2019-07-11</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>108</td>\n",
       "      <td>98.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>6169.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>988.0</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>All-comforts 2-bed flat near Wimbledon tennis</td>\n",
       "      <td>10 mins walk to Southfields tube and Wimbledon...</td>\n",
       "      <td>Large, all comforts, 2-bed flat; first floor; ...</td>\n",
       "      <td>none</td>\n",
       "      <td>Non-smokers only. No pets.</td>\n",
       "      <td>Free off-street parking; buses to Richmond/Too...</td>\n",
       "      <td>Entire flat; use of communal gardens.</td>\n",
       "      <td>I'm happy to provide you with any helpful hint...</td>\n",
       "      <td>No smoking. No parties. No loud music after 10...</td>\n",
       "      <td>3550</td>\n",
       "      <td>Hi, I'm a sociologist/anthropologist, NLP exec...</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>100.0</td>\n",
       "      <td>f</td>\n",
       "      <td>395</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['email', 'phone', 'reviews']</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>149.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>51.446870000000004</td>\n",
       "      <td>-0.21874</td>\n",
       "      <td>t</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>{TV,Wifi,Kitchen,\"Free parking on premises\",El...</td>\n",
       "      <td>65.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3 weeks ago</td>\n",
       "      <td>t</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-07-11</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1145</td>\n",
       "      <td>153</td>\n",
       "      <td>91.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>623.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name                                              space                                        description experiences_offered                                              notes                                            transit                                             access                                        interaction                                        house_rules host_since                                         host_about  host_response_time  host_response_rate host_is_superhost host_neighbourhood  host_listings_count  host_total_listings_count                                 host_verifications host_has_profile_pic host_identity_verified  neighbourhood  neighbourhood_cleansed   city           state         country            latitude  longitude is_location_exact  property_type        room_type  accommodates  bathrooms  bedrooms  beds  bed_type                                          amenities   price security_deposit  \\\n",
       "0                Holiday London DB Room Let-on going  Hello Everyone, I'm offering my lovely double ...  My bright double bedroom with a large window h...            business  For art lovers I can give guest my Tate Member...  The flat only a 10 minute walk to Finsbury Par...  Guest will have access to the self catering ki...  I like to have little chats with my guest over...  I'm an artist and have my artwork up on the wa...       3658  I am a Multi-Media Visual Artist and Creative ...  within a few hours                86.0                 f                193                  4.0                        4.0          ['email', 'phone', 'facebook', 'reviews']                    t                      f           73.0                    18.0  244.0  Greater London  United Kingdom  51.568020000000004   -0.11121                 t            1.0     Private room           2.0        1.0       1.0   0.0  Real Bed  {TV,\"Cable TV\",Wifi,Kitchen,\"Paid parking off ...   65.00           100.00   \n",
       "1                Bright Chelsea  Apartment. Chelsea!  Bright Chelsea Apartment  This is a bright one...  Lots of windows and light.  St Luke's Gardens ...            romantic  The building next door is in the process of be...  The underground stations are South Kensington ...  There are two wardrobes for guests exclusive u...  If I am in the country I like to welcome my gu...  NO SMOKING PLEASE.. No unauthorised guests. No...       3846  English, grandmother,  I have travelled quite ...        within a day               100.0                 t                 54                  1.0                        1.0  ['email', 'phone', 'reviews', 'jumio', 'govern...                    t                      t          110.0                    19.0  284.0            none  United Kingdom            51.48796   -0.16898                 t            1.0  Entire home/apt           2.0        1.0       1.0   1.0  Real Bed  {TV,\"Cable TV\",Internet,Wifi,\"Air conditioning...  100.00           150.00   \n",
       "2              Superb 3-Bed/2 Bath & Wifi: Trendy W1  Ready again from June 2018 for bookings after ...  Open from June 2018 after a 3-year break, we a...                none  This property has new flooring throughout. Gue...  You can walk to tourist London or take numerou...            Full use of whole independent apartment  Always available by email or phone (before, du...  The apartment benefits from new flooring throu...       3522  We are Liz and Jack.  We manage a number of ho...      within an hour                85.0                 t                110                 19.0                       19.0  ['email', 'phone', 'reviews', 'jumio', 'offlin...                    t                      t           35.0                    32.0  284.0       Fitzrovia  United Kingdom            51.52098   -0.14002                 t            1.0  Entire home/apt           6.0        2.0       3.0   3.0  Real Bed  {TV,Wifi,Kitchen,\"Paid parking off premises\",E...  300.00           350.00   \n",
       "3  Battersea bedroom & office w parking shared ga...  - End of terrace two bedroom house close to So...  Artist house, bright high ceiling rooms, priva...              family  - Please have a profile or tell us more about ...  - 5 mins walk to Battersea Park, 15 mins walk ...  - there is a communal garden in our complex - ...  We rent out our house only when we are away. T...  A house manual will be emailed once a booking ...       3707  I've been using Airbnb for a while now, both a...        within a day               100.0                 f                 14                  2.0                        2.0  ['email', 'phone', 'reviews', 'jumio', 'offlin...                    t                      t           84.0                    31.0  284.0            none  United Kingdom            51.47298   -0.16376                 t           36.0  Entire home/apt           2.0        1.5       1.0   1.0  Real Bed  {TV,\"Cable TV\",Internet,Wifi,Kitchen,\"Free par...  175.00           250.00   \n",
       "4      All-comforts 2-bed flat near Wimbledon tennis  10 mins walk to Southfields tube and Wimbledon...  Large, all comforts, 2-bed flat; first floor; ...                none                         Non-smokers only. No pets.  Free off-street parking; buses to Richmond/Too...              Entire flat; use of communal gardens.  I'm happy to provide you with any helpful hint...  No smoking. No parties. No loud music after 10...       3550  Hi, I'm a sociologist/anthropologist, NLP exec...  within a few hours               100.0                 f                395                  1.0                        1.0                      ['email', 'phone', 'reviews']                    t                      f          149.0                    31.0  547.0          London  United Kingdom  51.446870000000004   -0.21874                 t            1.0  Entire home/apt           4.0        1.0       2.0   2.0  Real Bed  {TV,Wifi,Kitchen,\"Free parking on premises\",El...   65.00           250.00   \n",
       "\n",
       "   cleaning_fee guests_included extra_people  minimum_nights  maximum_nights  minimum_minimum_nights  maximum_minimum_nights minimum_maximum_nights  maximum_maximum_nights  minimum_nights_avg_ntm  maximum_nights_avg_ntm calendar_updated has_availability  availability_30  availability_60  availability_90  availability_365 calendar_last_scraped  number_of_reviews number_of_reviews_ltm first_review last_review review_scores_rating review_scores_accuracy review_scores_cleanliness  review_scores_checkin  review_scores_communication  review_scores_location  review_scores_value requires_license instant_bookable is_business_travel_ready          cancellation_policy require_guest_profile_picture require_guest_phone_verification  calculated_host_listings_count  calculated_host_listings_count_entire_homes  calculated_host_listings_count_private_rooms  calculated_host_listings_count_shared_rooms  reviews_per_month  host_name_cat  host_country  host_city  states  \n",
       "0          15.0               1        15.00             1.0            29.0                     1.0                     1.0                     29                    29.0                     1.0                    29.0     2 months ago                t             19.0             42.0             72.0             347.0            2019-07-11               16.0                     2         3336          47                 96.0                    9.0                      10.0                    9.0                         10.0                     9.0                  9.0                f                f                        f                     moderate                             f                                f                             3.0                                          1.0                                           2.0                                          0.0               0.15          518.0         504.0      988.0    78.0  \n",
       "1          50.0               2         0.00             3.0            50.0                     3.0                     3.0                     50                    50.0                     3.0                    50.0     2 months ago                t              1.0              9.0              9.0             203.0            2019-07-11               85.0                     4         3422         201                 96.0                   10.0                      10.0                   10.0                         10.0                    10.0                  9.0                f                f                        f  strict_14_with_grace_period                             t                                t                             1.0                                          1.0                                           0.0                                          0.0               0.73        10239.0         504.0      871.0   166.0  \n",
       "2          65.0               4        10.00             3.0           365.0                     2.0                     3.0                    365                   365.0                     3.0                   365.0            today                t              3.0             14.0             31.0             269.0            2019-07-11               41.0                    12         3012         156                 94.0                   10.0                       9.0                    9.0                          9.0                    10.0                  9.0                f                t                        f  strict_14_with_grace_period                             f                                f                            14.0                                         14.0                                           0.0                                          0.0               0.41         7459.0         504.0      988.0    67.0  \n",
       "3          70.0               2         0.00            30.0          1125.0                    30.0                    30.0                   1125                  1125.0                    30.0                  1125.0     4 months ago                t              1.0             24.0             54.0             329.0            2019-07-11               93.0                     1         3186         108                 98.0                   10.0                      10.0                   10.0                         10.0                     9.0                  9.0                f                f                        f                     moderate                             t                                t                             1.0                                          1.0                                           0.0                                          0.0               0.88         6169.0         504.0      988.0   166.0  \n",
       "4          50.0               2        11.00             4.0           100.0                     4.0                     4.0                    100                   100.0                     4.0                   100.0      3 weeks ago                t              1.0              2.0              2.0               2.0            2019-07-11               28.0                     3         1145         153                 91.0                   10.0                       9.0                    9.0                          9.0                     9.0                  9.0                f                f                        f                     moderate                             f                                f                             1.0                                          1.0                                           0.0                                          0.0               0.69          623.0         191.0     1396.0   136.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_availability'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing 2 rows which got corrupted\n",
    "df = df.drop([df.index[4382],df.index[4381]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.info()\n",
    "#df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = ['host_verifications','amenities']\n",
    "\n",
    "    \n",
    "for ind in df.index:\n",
    "    \n",
    "    lis = str(df['host_verifications'][ind]).split(\", \")\n",
    "    df['host_verifications'][ind] = len(lis)\n",
    "    \n",
    "for ind in df.index:\n",
    "    \n",
    "    lis = str(df['amenities'][ind]).split(\",\")\n",
    "    df['amenities'][ind] = len(lis)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperating out textual data from main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['name','space','description','notes','transit','access','interaction','house_rules','host_about']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['name','space','description','notes','transit','access','interaction','house_rules','host_about']\n",
    "df2.fillna('none', inplace=True)\n",
    "\n",
    "#df2.name = df2.str.lower()\n",
    "df2.isnull().sum()\n",
    "\n",
    "#df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This below function is to remove below mentioned special chars, stopwords and patterns from text data, then tokenize and lemmatize the text sequence (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    ## Remove puncuation\n",
    "    text = text.translate(string.punctuation)\n",
    "    \n",
    "    ## Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "    \n",
    "    ## Remove stop words\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops and len(w) >= 3]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "    ## Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    ## Stemming\n",
    "    text = text.split()\n",
    "    #stemmer = SnowballStemmer('english')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemma_words=[lemmatizer.lemmatize(word) for word in text]\n",
    "    text = \" \".join(lemma_words)\n",
    "    #stemmed_words = [stemmer.stem(word) for word in text]\n",
    "    #text = \" \".join(stemmed_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.stem import SnowballStemmer\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputx= {new_list: [] for new_list in texts}\n",
    "embeddings ={new_list: [] for new_list in texts}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate word embeddings(GloVe) from one hot word sequence (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sents in texts:\n",
    "    X_train = df2[sents]\n",
    "\n",
    "    word_tokenizer = Tokenizer()\n",
    "    word_tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    vocab_length = len(word_tokenizer.word_index) + 1\n",
    "    embeddings_dictionary = dict()\n",
    "    glove_file = open('/home/jbmai_sai/Documents/london/glove.6B/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "    \n",
    "    for line in glove_file:\n",
    "        records = line.split()\n",
    "        word = records[0]\n",
    "        vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "        embeddings_dictionary [word] = vector_dimensions\n",
    "        \n",
    "    glove_file.close()\n",
    "    embedded_sentences = [one_hot(sent, vocab_size) for sent in X_train]\n",
    "    padded_sentences = pad_sequences(embedded_sentences, 25, padding='post')\n",
    "    \n",
    "    embedding_matrix = zeros((vocab_length, 100))\n",
    "    \n",
    "    for word, index in word_tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_dictionary.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            \n",
    "            embedding_matrix[index] = embedding_vector\n",
    "            \n",
    "    inputx[sents] = padded_sentences\n",
    "    embeddings[sents] = embedding_matrix\n",
    "    \n",
    " \n",
    "\n",
    "'''\n",
    "\n",
    "X_train = df2['name']\n",
    "\n",
    "word_tokenizer = Tokenizer()\n",
    "word_tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "vocab_length = len(word_tokenizer.word_index) + 1\n",
    "\n",
    "\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "glove_file = open('/home/jbmai_sai/Documents/london/glove.6B/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "\n",
    "glove_file.close()\n",
    "\n",
    "embedded_sentences = [one_hot(sent, vocab_size) for sent in X_train]\n",
    "\n",
    "padded_sentences = pad_sequences(embedded_sentences, 25, padding='post')\n",
    "\n",
    "embedding_matrix = zeros((vocab_length, 100))\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector\n",
    "'''     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# persist both embeddings and text encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for i in texts:\n",
    "    a = inputx[i]\n",
    "    print(type(a))\n",
    "    st = \"inputx_\"+i\n",
    "    np.save('/home/jbmai_sai/Documents/london/'+st,a) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for i in texts:\n",
    "    a = embeddings[i]\n",
    "    print(type(a))\n",
    "    st = \"embeddings_\"+i\n",
    "    np.save('/home/jbmai_sai/Documents/london/'+st,a) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END of NLP preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['host_response_time'].fillna('none', inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in df.index: \n",
    "    \n",
    "    \n",
    "    s = str(df['security_deposit'][ind])\n",
    "    s1 = s.replace(',','')\n",
    "    df['security_deposit'][ind] = s1\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['security_deposit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filling the missing numerical values with mode or median or mode based on their frequency and also generating One-Hot vectors for low variable categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['security_deposit'] = df['security_deposit'].astype(float)\n",
    "df['review_scores_cleanliness'] = df['review_scores_cleanliness'].astype(float)\n",
    "df['review_scores_accuracy'] = df['review_scores_accuracy'].astype(float)\n",
    "df['review_scores_rating'] = df['review_scores_rating'].astype(float)\n",
    "\n",
    "\n",
    "df['bathrooms'].fillna(df['bathrooms'].mode()[0], inplace=True)\n",
    "df['bedrooms'].fillna(df['bedrooms'].mode()[0], inplace=True)\n",
    "df['beds'].fillna(df['beds'].mode()[0], inplace=True)\n",
    "df['security_deposit'].fillna(df['security_deposit'].mean(), inplace=True)\n",
    "df['cleaning_fee'].fillna(df['cleaning_fee'].mean(), inplace=True)\n",
    "df['reviews_per_month'].fillna(df['reviews_per_month'].median(), inplace=True)\n",
    "df['review_scores_rating'].fillna(df['review_scores_rating'].median(), inplace=True)\n",
    "df['review_scores_accuracy'].fillna(df['review_scores_accuracy'].median(), inplace=True)\n",
    "df['review_scores_cleanliness'].fillna(df['review_scores_cleanliness'].median(), inplace=True)\n",
    "df['review_scores_checkin'].fillna(df['review_scores_checkin'].median(), inplace=True)\n",
    "df['review_scores_communication'].fillna(df['review_scores_communication'].median(), inplace=True)\n",
    "df['review_scores_location'].fillna(df['review_scores_location'].median(), inplace=True)\n",
    "df['review_scores_value'].fillna(df['review_scores_value'].median(), inplace=True)\n",
    "df['host_total_listings_count'].fillna(df['host_total_listings_count'].mean(), inplace=True)\n",
    "df['host_listings_count'].fillna(df['host_listings_count'].mean(), inplace=True)\n",
    "df['host_response_rate'].fillna(df['host_response_rate'].mean(), inplace=True)\n",
    "list=['host_is_superhost','host_has_profile_pic','host_identity_verified','is_location_exact','has_availability','requires_license','instant_bookable','is_business_travel_ready','require_guest_profile_picture','require_guest_phone_verification']\n",
    "\n",
    "\n",
    "\n",
    "df = pd.concat([df,pd.get_dummies(df['experiences_offered'], prefix='experiences_offered')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['host_response_time'], prefix='host_response_time')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['room_type'], prefix='room_type')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['bed_type'], prefix='bed_type')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['calendar_last_scraped'], prefix='calendar_last_scraped')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['cancellation_policy'], prefix='cancellation_policy')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['country'], prefix='country')],axis=1)\n",
    "\n",
    "for col in list:\n",
    "    df = pd.concat([df,pd.get_dummies(df[col], prefix=col)],axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['experiences_offered','country','host_response_time','room_type','bed_type','calendar_last_scraped','cancellation_policy','host_is_superhost','host_has_profile_pic','host_identity_verified','is_location_exact','has_availability','requires_license','instant_bookable','is_business_travel_ready','require_guest_profile_picture','require_guest_phone_verification'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['name','space','description','notes','transit','access','interaction','house_rules','host_about'],inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persisting the data Preprocessed Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/home/jbmai_sai/Documents/london/preprocess_3.csv',index = False)\n",
    "df2 = pd.read_csv('/home/jbmai_sai/Documents/london/preprocess_3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------END of Data Preprocessing and Feature Extraction------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    ## Remove puncuation\n",
    "    text = text.translate(string.punctuation)\n",
    "    \n",
    "    ## Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "    \n",
    "    ## Remove stop words\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops and len(w) >= 3]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "    ## Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    ## Stemming\n",
    "    text = text.split()\n",
    "    #stemmer = SnowballStemmer('english')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemma_words=[lemmatizer.lemmatize(word) for word in text]\n",
    "    text = \" \".join(lemma_words)\n",
    "    #stemmed_words = [stemmer.stem(word) for word in text]\n",
    "    #text = \" \".join(stemmed_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatize Single Word\n",
    "#print(lemmatizer.lemmatize(\"bats\"))\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "df2['name'] = df2['name'].map(lambda x: clean_text(str(x)))\n",
    "\n",
    "for row in df2['name']:\n",
    "    tokenize_word = word_tokenize(row)\n",
    "    for word in tokenize_word:\n",
    "        all_words.append(word)\n",
    "        \n",
    "unique_words = set(all_words)\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "#labels = array(df2['name'])\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "X_train = df2['name']\n",
    "\n",
    "word_tokenizer = Tokenizer()\n",
    "word_tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "vocab_length = len(word_tokenizer.word_index) + 1\n",
    "\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "glove_file = open('/home/jbmai_sai/Documents/london/glove.6B/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "\n",
    "glove_file.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab_size = 9900\n",
    "\n",
    "#X_train = [one_hot(d, vocab_size,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',lower=True, split=' ') for d in X_train]\n",
    "#X_test = [one_hot(d, vocab_size,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',lower=True, split=' ') for d in X_test]\n",
    "embedded_sentences = [one_hot(sent, vocab_size) for sent in X_train]\n",
    "\n",
    "#from nltk.tokenize import word_tokenize\n",
    "\n",
    "#word_count = lambda sentence: len(word_tokenize(sentence))\n",
    "#longest_sentence = max(corpus, key=word_count)\n",
    "#length_long_sentence = len(word_tokenize(longest_sentence))\n",
    "\n",
    "padded_sentences = pad_sequences(embedded_sentences, 25, padding='post')\n",
    "\n",
    "print(padded_sentences[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = zeros((vocab_length, 100))\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[1])\n",
    "print(X_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {new_list: [] for new_list in texts} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
